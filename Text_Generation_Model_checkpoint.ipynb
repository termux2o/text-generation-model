{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7817c1ff-b97b-44fc-b64b-93e9ca349c97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7817c1ff-b97b-44fc-b64b-93e9ca349c97",
        "outputId": "f8af4f26-c5d4-4d00-ccfd-7968c0f70a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install requests torch nltk beautifulsoup4\n",
        "\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65fdfb46-9ee4-457b-a4d0-95930b211cf9",
      "metadata": {
        "id": "65fdfb46-9ee4-457b-a4d0-95930b211cf9"
      },
      "source": [
        "*Data Collection via API*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e545053d-db0d-410d-aa91-c6b9e0bb6b84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e545053d-db0d-410d-aa91-c6b9e0bb6b84",
        "outputId": "4aa1f7d8-9111-4b46-920e-32aa8e64084b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** START OF THE PROJECT GUTENBERG EBOOK 1342 ***\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "                             GEORGE ALLEN\r\n",
            "                               PUBLISHER\r\n",
            "\r\n",
            "                        156 CHARING CROSS ROAD\r\n",
            "                                LONDON\r\n",
            "\r\n",
            "                             RUSKIN HOUSE\r\n",
            "                                   ]\r\n",
            "\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "               _Reading Janeâ€™s Letters._      _Chap 34._\r\n",
            "                                   ]\r\n",
            "\r\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "def fetch_book_text(url):\n",
        "    response = requests.get(url)\n",
        "    text = response.text  \n",
        "    return text\n",
        "\n",
        "book_url = 'https://www.gutenberg.org/files/1342/1342-0.txt'  \n",
        "book_text = fetch_book_text(book_url)\n",
        "print(book_text[:500])  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e63e6ba-dfb8-4966-9e61-2c92dfc225aa",
      "metadata": {
        "id": "0e63e6ba-dfb8-4966-9e61-2c92dfc225aa"
      },
      "source": [
        "*Preprocessing the Data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1977ddb8-a1be-4b60-93fe-3cb6c8b26dd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1977ddb8-a1be-4b60-93fe-3cb6c8b26dd7",
        "outputId": "e3338f06-eedd-42f9-f5a1-e99660b2b609"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ja6Py9OI5Aha",
      "metadata": {
        "id": "Ja6Py9OI5Aha"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j0k2ehht5BJw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0k2ehht5BJw",
        "outputId": "17bf9c45-6e43-480e-e794-d076d2b725f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk requests beautifulsoup4\n",
        "\n",
        "import requests\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3gsyGQKz4MFH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gsyGQKz4MFH",
        "outputId": "4112d805-00fd-43db-e571-b0621d550104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cleaned data preview:\n",
            "start project gutenberg ebook illustr georg allen publish chare cross road london ruskin hous illustr read jane letter chap pride prejudic jane austen prefac georg saintsburi illustr hugh thomson illustr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "sample_text = book_text[:1000]\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  \n",
        "    text = re.sub(r'@\\S+', '', text)  \n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  \n",
        "    text = text.lower().split()\n",
        "    text = [stemmer.stem(word) for word in text if word not in stop_words]\n",
        "\n",
        "    return ' '.join(text)\n",
        "\n",
        "cleaned_text = preprocess_text(sample_text)\n",
        "print(\"\\nCleaned data preview:\")\n",
        "print(cleaned_text[:500])  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7662c012-46a9-45d0-affe-54216f4e81ff",
      "metadata": {
        "id": "7662c012-46a9-45d0-affe-54216f4e81ff"
      },
      "source": [
        "*Prepare Data for the LSTM Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfdf1a1-171c-4271-a6e7-aaedc3bbfb99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcfdf1a1-171c-4271-a6e7-aaedc3bbfb99",
        "outputId": "6122d757-0612-465c-dd82-3766a7cdefc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('start project gutenberg ebook illustr georg allen ', 'p'), ('tart project gutenberg ebook illustr georg allen p', 'u'), ('art project gutenberg ebook illustr georg allen pu', 'b'), ('rt project gutenberg ebook illustr georg allen pub', 'l'), ('t project gutenberg ebook illustr georg allen publ', 'i')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def create_sequences(tokens, seq_length=50):\n",
        "    sequences = []\n",
        "    for i in range(len(tokens) - seq_length):\n",
        "        seq_in = tokens[i:i + seq_length]\n",
        "        seq_out = tokens[i + seq_length]\n",
        "        sequences.append((seq_in, seq_out))\n",
        "    return sequences\n",
        "\n",
        "sequences = create_sequences(cleaned_text)\n",
        "print(sequences[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f0e151-9d8d-47d8-9feb-a654453f676b",
      "metadata": {
        "id": "95f0e151-9d8d-47d8-9feb-a654453f676b"
      },
      "source": [
        "*Define the LSTM Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fae8f8-b6f7-4ee0-a94d-b2045101b857",
      "metadata": {
        "id": "e9fae8f8-b6f7-4ee0-a94d-b2045101b857"
      },
      "outputs": [],
      "source": [
        "class TextGenerationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(TextGenerationModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])  \n",
        "        return out\n",
        "\n",
        "vocab = set(cleaned_text)\n",
        "vocab_size = len(vocab)\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "index_to_word = {i: word for word, i in word_to_index.items()}\n",
        "\n",
        "def sequences_to_indices(sequences, word_to_index):\n",
        "    X = []\n",
        "    y = []\n",
        "    for seq_in, seq_out in sequences:\n",
        "        X.append([word_to_index[word] for word in seq_in])\n",
        "        y.append(word_to_index[seq_out])\n",
        "    return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "X, y = sequences_to_indices(sequences, word_to_index)\n",
        "embed_size = 128\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "model = TextGenerationModel(vocab_size, embed_size, hidden_size, num_layers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45e69ad-6009-4a02-a6e4-2926e92b0bee",
      "metadata": {
        "id": "f45e69ad-6009-4a02-a6e4-2926e92b0bee"
      },
      "source": [
        "*Training the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b8e934-018f-468e-9cbc-021292910579",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9b8e934-018f-468e-9cbc-021292910579",
        "outputId": "c8805a90-acd9-4714-b732-6342fcc9d2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 3.0397\n",
            "Epoch [2/10], Loss: 2.9924\n",
            "Epoch [3/10], Loss: 2.9514\n",
            "Epoch [4/10], Loss: 2.8830\n",
            "Epoch [5/10], Loss: 2.7907\n",
            "Epoch [6/10], Loss: 2.7067\n",
            "Epoch [7/10], Loss: 2.6954\n",
            "Epoch [8/10], Loss: 2.5781\n",
            "Epoch [9/10], Loss: 2.5064\n",
            "Epoch [10/10], Loss: 2.4076\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, X, y, epochs=10, batch_size=64, lr=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    dataset = torch.utils.data.TensorDataset(X, y)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
        "\n",
        "train_model(model, X, y, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d4c885-cef3-41ff-9044-060d32626910",
      "metadata": {
        "id": "b1d4c885-cef3-41ff-9044-060d32626910"
      },
      "source": [
        "Generate Text Using the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d757d8-3078-4665-be0c-6337b66d8376",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8d757d8-3078-4665-be0c-6337b66d8376",
        "outputId": "7660537d-ae27-4378-e7f1-822edfdc2473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "it is a truth universally acknowledged   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s   u s  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "def generate_text(model, seed, word_to_index, index_to_word, seq_length=50, max_length=100):\n",
        "    model.eval()\n",
        "    seed = seed.lower()\n",
        "    input_seq = [word_to_index[word] for word in seed.split() if word in word_to_index]\n",
        "    if len(input_seq) == 0:\n",
        "        return \"Error: Seed text contains unknown words.\"\n",
        "\n",
        "    input_tensor = torch.tensor(input_seq).unsqueeze(0)\n",
        "\n",
        "    generated_text = seed\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            predicted_word_idx = output.argmax(dim=1).item()\n",
        "            predicted_word = index_to_word[predicted_word_idx]\n",
        "            generated_text += ' ' + predicted_word\n",
        "\n",
        "            input_seq = input_seq[1:] + [predicted_word_idx]\n",
        "            input_tensor = torch.tensor(input_seq).unsqueeze(0)\n",
        "\n",
        "    return generated_text\n",
        "generated = generate_text(model, \"It is a truth universally acknowledged\", word_to_index, index_to_word)\n",
        "print(generated)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48b7583f-980b-4251-a345-29bcabf16c6a",
      "metadata": {
        "id": "48b7583f-980b-4251-a345-29bcabf16c6a"
      },
      "source": [
        "*Evaluate the Model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4b85d1-6a12-4cf7-9e39-94a452b5a711",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4b85d1-6a12-4cf7-9e39-94a452b5a711",
        "outputId": "f18fcc34-f074-4790-f8fc-5df22797262a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity: 10.44\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import math\n",
        "\n",
        "def calculate_perplexity(model, X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        log_probabilities = torch.log_softmax(outputs, dim=1)\n",
        "        loss = torch.nn.functional.nll_loss(log_probabilities, y)\n",
        "        perplexity = math.exp(loss.item())\n",
        "    return perplexity\n",
        "\n",
        "perplexity = calculate_perplexity(model, X, y)\n",
        "print(f\"Perplexity: {perplexity:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff49c73f-3957-4b3d-b792-8cb7026f84bf",
      "metadata": {
        "id": "ff49c73f-3957-4b3d-b792-8cb7026f84bf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
